{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#OLYMPIC SQUATS ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 19:19:03.118987: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 19:19:03.973070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/mukundan/anaconda3/envs/aifit/lib/\n",
      "2023-04-27 19:19:03.973156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/mukundan/anaconda3/envs/aifit/lib/\n",
      "2023-04-27 19:19:03.973163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, InputLayer, LSTM, Bidirectional, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import vis_squat as vis\n",
    "import lstm_model as mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [00:00<00:00, 257.51it/s]\n"
     ]
    }
   ],
   "source": [
    "path_save='/home/mukundan/Desktop/VIII_SEM/Data/labelled_data/media'\n",
    "visual=vis.VisSquat()\n",
    "df=visual.get_dat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_lst=list(visual.kpts.keys())[:-2]\n",
    "grp=[]\n",
    "key_lst_n=[]\n",
    "for i, key in enumerate(key_lst):\n",
    "    grp.append(key)\n",
    "    if i%3==2:\n",
    "        key_lst_n.append(grp)\n",
    "        grp=[]\n",
    "    key_lst=key_lst_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'extend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(key)\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m): \n\u001b[1;32m     17\u001b[0m     x_X\u001b[39m.\u001b[39mextend(load_key)\n\u001b[0;32m---> 18\u001b[0m     x_y\u001b[39m.\u001b[39;49mextend(load_key)\n\u001b[1;32m     19\u001b[0m     x_y\u001b[39m=\u001b[39mx_y[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mappend(\u001b[39m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mstr\u001b[39m(key)\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m): \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'extend'"
     ]
    }
   ],
   "source": [
    "for num, keys in enumerate(key_lst):\n",
    "    x_X=[]\n",
    "    y_X=[]\n",
    "    z_X=[]\n",
    "    x_y=[]\n",
    "    y_y=[]\n",
    "    z_y=[]\n",
    "    for key in keys:\n",
    "        start=0\n",
    "        end=0\n",
    "        for i, j in enumerate(list(visual.df['i'])):\n",
    "            if j==0 and i!=0: \n",
    "                end=i-1\n",
    "                load_key=list(visual.df[key][start+4:end])\n",
    "                start=end\n",
    "                if str(key).endswith('x'): \n",
    "                    x_X.extend(load_key)\n",
    "                    x_y.extend(load_key)\n",
    "                    x_y=x_y[:-1].append(0)\n",
    "                elif str(key).endswith('y'): \n",
    "                    y_X.extend(load_key)\n",
    "                    y_y.extend(load_key)\n",
    "                    y_y=x_y[:-1].append(0)\n",
    "                elif str(key).endswith('z'):\n",
    "                    z_X.extend(load_key)\n",
    "                    z_y.extend(load_key)\n",
    "                    z_y=x_y[:-1].append(0)\n",
    "\n",
    "    print(x_X, y_X, z_X, x_y, y_y, z_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df.keys():\n",
    "    if key=='i' or key=='name': continue\n",
    "    print('=================================================================')\n",
    "    print('Training for '+ key)\n",
    "    print('=================================================================')\n",
    "    model=mod.get_model.lstm_cell(mod, model_name=key)\n",
    "    start, end =0,0\n",
    "    save_name=key+'.h5'\n",
    "    mc = ModelCheckpoint(save_name, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    for i, j in enumerate(df['i']):\n",
    "        if j==0 and i!=0: \n",
    "            end=i-1\n",
    "            dat=df[key][start: end]\n",
    "            start=end\n",
    "            X=np.array(dat).astype(np.float64).reshape(-1, 1)\n",
    "            y=dat[:-1]\n",
    "            y=np.array(y).astype(np.float64).reshape(-1, 1)\n",
    "            print(X.shape, y.shape)\n",
    "            y=np.append(y, [-1])\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.2, shuffle=True)\n",
    "            \n",
    "            history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=X.shape[0], epochs=10, verbose=1, shuffle=True, callbacks=[mc])\n",
    "            loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "#es_va = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)\n",
    "#mc = ModelCheckpoint('model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=300, epochs=200, verbose=1, shuffle=True)#, callbacks=[mc])\n",
    "#saved_model = load_model('model.h5')\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" y_pred=model.predict(X_test)\n",
    "\n",
    "'''\n",
    "for i, y in enumerate(y_test):\n",
    "    inverted = label_encoder.inverse_transform([np.argmax(y[0:])])\n",
    "    y_test_inv.append(str(inverted))\n",
    "    y_test_integer.append(np.argmax(y[0:]))\n",
    "\n",
    "for i, y in enumerate(y_pred):\n",
    "    inverted = label_encoder.inverse_transform([np.argmax(y[0:])])\n",
    "    y_pred_inv.append(str(inverted))\n",
    "    y_pred_integer.append(np.argmax(y[0:]))\n",
    "'''\n",
    "cf_df={'y_pred': y_pred,\n",
    "       'y_test': y_test}\n",
    "\n",
    "#cf_df=pd.DataFrame(cf_df)\n",
    "print(cf_df) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], marker='.')\n",
    "plt.plot(history.history['val_accuracy'], marker='.')\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()\n",
    "plt.legend(['acc', 'val_acc'], loc='lower right')\n",
    "#plt.savefig(os.path.join(path_save, 'model_accuracy_lstm_6.png'))\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], marker='.')\n",
    "plt.plot(history.history['val_loss'], marker='.')\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "#plt.savefig(os.path.join(path_save, 'model_loss_lstm_6.png'))\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[-33.098077898188166, -65.44725705933772, 144.44627308952465, -31.77462841751018, -63.828643237381186, 145.78701336608785, -34.1017031670986, -62.85006136716562, 143.65252603902775, -24.533596245715415, -57.87578779807893, 153.0895174999673, -42.44750928025705, -55.90475265338852, 146.70398676454698, -22.847586186716853, -40.706638315604934, 140.63701195494775, -34.386572666179475, -39.654323132533804, 128.7272921663957, -35.930406637552494, -49.72467221807416, 142.39623331564488, -27.250395166471886, -52.83593203381766, 144.07441044344952, -27.36273384675532, -25.061787859943312, 155.6239223417995, -37.876814184041926, -23.666101542744705, 149.1332752310651, -27.686047705438952, -1.5791161838444963, 161.5604528581057, -39.01192009807589, -0.7007367527796415, 152.3842528384619, -26.144767035171707, 19.6444657766348, 160.85365283053812, -41.22631352718785, 20.3417540920933, 158.0220106309576, -27.444019110175738, 22.35788949808039, 158.93113348622, -38.82036501949839, 23.112616602474716, 156.912005070014, -20.5952235212783, 28.88515395203289, 156.93969302396465, -42.17681155370266, 28.502246258244725, 147.1140654570194]\n",
    "x_test=np.array(x_test).reshape((-1, 19,3))\n",
    "z=model.predict(x_test)\n",
    "print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aifit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
